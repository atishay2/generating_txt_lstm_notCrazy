{"cells":[{"metadata":{"_uuid":"cb992059cbdce9902dd23be8246fc180e6c96aa6"},"cell_type":"markdown","source":"# Text Generation using an LSTM in Keras\nIn this kernel you we will go over how to let a network create text in the style of sir arthur conan doyle. This kernel is heavily based on the [official keras text generation example](https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py).  I also made [a video](https://youtu.be/QtQt1CUEE3w) on text generation using an LSTM network.\nContent:\n1. [Introduction](#1)\n2. [Loading in data](#2)\n3. [Preprocessing](#3)  \n    3.1 [Map chars to integers](#3.1)  \n    3.2 [Split up into subsequences](#3.2)\n4. [Building model](#4)  \n    4.1 [Helper Functions](#4.1)  \n    4.2 [Defining callbacks and training the model](#4.2)\n5. [Generate new text](#5)  \n6. [Conclusion](#6)"},{"metadata":{"_uuid":"2066f1978370082a41b410a67e440e7ed4cb72c7"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"027dbe6d5cefff7d3eac6147ef54a023dcf36d7d"},"cell_type":"markdown","source":"<a id=\"1\"></a> \n## 1. Introduction\nBecause the sequence in an text is important we will recurrent neural network which can remember its previous inputs."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from __future__ import print_function\nfrom keras.callbacks import LambdaCallback\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation\nfrom keras.layers import LSTM\nfrom keras.optimizers import RMSprop\nfrom keras.utils.data_utils import get_file\nimport numpy as np\nimport random\nimport sys\nimport io","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"<a id=\"2\"></a> \n## 2. Loading in data"},{"metadata":{"trusted":true,"_uuid":"e0f294d2dcfa87c33bd3c0906379f44986d1b8d6"},"cell_type":"code","source":"text = open('../input/sherlock_homes.txt', 'r').read().lower()\nprint('text length', len(text))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee0e4330b29978330549ec6c7014e5a0c9496d06"},"cell_type":"code","source":"print(text[:300])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"144150bd91525a6a2f026162efec60d443008dae"},"cell_type":"markdown","source":"<a id=\"3\"></a> \n## 3. Preprocessing"},{"metadata":{"_uuid":"b40a7e3f910b134f8dbce978e13d01d42088b667"},"cell_type":"markdown","source":"<a id=\"3.1\"></a> \n### 3.1 Map chars to integers\n\nBecause we will be training on a character level we need to relate each unique character with a number.\nWe are going to create two dicts one from character to integer and one to transform back to character"},{"metadata":{"trusted":true,"_uuid":"2f424b2f58c7039f62b564a1aeceb5b3c5d86901"},"cell_type":"code","source":"chars = sorted(list(set(text)))\nprint('total chars: ', len(chars))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"402f6e5ce9e8f7cdc2e7dcb55266aad1a8e3bb09"},"cell_type":"code","source":"char_indices = dict((c, i) for i, c in enumerate(chars))\nindices_char = dict((i, c) for i, c in enumerate(chars))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a7a3ab9e3f6ad6e22a53090e50f4d6d5afdc3283"},"cell_type":"markdown","source":"<a id=\"3.2\"></a> \n### 3.2 Split up into subsequences\nCreates an array of sentence data with the length maxlen as well as an array with the next character."},{"metadata":{"trusted":true,"_uuid":"1fb13b2a1bd1ea7f801e751c1327ae59efc85a46"},"cell_type":"code","source":"maxlen = 40\nstep = 3\nsentences = []\nnext_chars = []\nfor i in range(0, len(text) - maxlen, step):\n    sentences.append(text[i: i + maxlen])\n    next_chars.append(text[i + maxlen])\nprint('nb sequences:', len(sentences))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1e627d19acc63ef301ca201de88147afac2990f7"},"cell_type":"code","source":"print(sentences[:3])\nprint(next_chars[:3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8def15c914a431fe23459e7aa456d9c480b0ec99"},"cell_type":"code","source":"# Print length\nprint(len(sentences))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ef6c437ef7a96590ddaa03b28a0d777f9a069e8b"},"cell_type":"markdown","source":"We need to reshape our data in a format we can pass to the Keras LSTM The shape look like [samples, time steps, features]"},{"metadata":{"trusted":true,"_uuid":"a730301d1db3f0f64faa5d6461ed6b8baefe72de"},"cell_type":"code","source":"x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\ny = np.zeros((len(sentences), len(chars)), dtype=np.bool)\nfor i, sentence in enumerate(sentences):\n    for t, char in enumerate(sentence):\n        x[i, t, char_indices[char]] = 1\n    y[i, char_indices[next_chars[i]]] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cef36cdb2cd80069386cb0b86573da6b575591f0"},"cell_type":"code","source":"print(x[:3])\nprint(y[:3])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0f18f120974528b74cae18b26a2ebff16a9f14a6"},"cell_type":"markdown","source":"<a id=\"4\"></a> \n## 4. Building model\nFor this kernel I will use a really small LSTM network but if you want to get better results feel free to replace it with a bigger network."},{"metadata":{"trusted":true,"_uuid":"08cc043586d3804558e0dde91563ac01c58f6a72"},"cell_type":"code","source":"model = Sequential()\nmodel.add(LSTM(128, input_shape=(maxlen, len(chars))))\nmodel.add(Dense(len(chars)))\nmodel.add(Activation('softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca6506184b319333e23a9531f69b956c6e8528bc"},"cell_type":"code","source":"optimizer = RMSprop(lr=0.01)\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizer)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5e3029c587f24cd5eb7a20645e907c2b5815ff77"},"cell_type":"markdown","source":"<a id=\"4.1\"></a> \n### 4.1 Helper Functions\n\nI got this function from the lstm_text_generation example from keras. [https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py](https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py)\n"},{"metadata":{"_uuid":"ddbf609aff0de89026f9367ab02c20fc5055c0cd"},"cell_type":"markdown","source":"Samples an index from a probability array with some temperature."},{"metadata":{"trusted":true,"_uuid":"10de369a6283954c1f5564d2f3d152cdf9f9efe2"},"cell_type":"code","source":"def sample(preds, temperature=1.0):\n    # helper function to sample an index from a probability array\n    preds = np.asarray(preds).astype('float64')\n    preds = np.log(preds) / temperature\n    exp_preds = np.exp(preds)\n    preds = exp_preds / np.sum(exp_preds)\n    probas = np.random.multinomial(1, preds, 1)\n    return np.argmax(probas)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e59c92fa7e68491270814a2bd209ece712df4672"},"cell_type":"markdown","source":"Callback function to print predicted text generated by our LSTM. It prints generated text with 5 different temperatures [0.2, 0.5, 1.0, 1.2]. 0.2 will generate text with more ordinary word. 1.2 will generate wilder guesses."},{"metadata":{"trusted":true,"_uuid":"993684b063bddea5f291c5e710c852da815e3362"},"cell_type":"code","source":"def on_epoch_end(epoch, logs):\n    # Function invoked at end of each epoch. Prints generated text.\n    print()\n    print('----- Generating text after Epoch: %d' % epoch)\n\n    start_index = random.randint(0, len(text) - maxlen - 1)\n    for diversity in [0.2, 0.5, 1.0, 1.2]:\n        print('----- diversity:', diversity)\n\n        generated = ''\n        sentence = text[start_index: start_index + maxlen]\n        generated += sentence\n        print('----- Generating with seed: \"' + sentence + '\"')\n        sys.stdout.write(generated)\n\n        for i in range(400):\n            x_pred = np.zeros((1, maxlen, len(chars)))\n            for t, char in enumerate(sentence):\n                x_pred[0, t, char_indices[char]] = 1.\n\n            preds = model.predict(x_pred, verbose=0)[0]\n            next_index = sample(preds, diversity)\n            next_char = indices_char[next_index]\n\n            generated += next_char\n            sentence = sentence[1:] + next_char\n\n            sys.stdout.write(next_char)\n            sys.stdout.flush()\n        print()\nprint_callback = LambdaCallback(on_epoch_end=on_epoch_end)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"31701fe51d0d0d7dea6bc8c50b5e135c96ecfa75"},"cell_type":"markdown","source":"<a id=\"4.2\"></a> \n### 4.2 Defining callbacks and training the model"},{"metadata":{"trusted":true,"_uuid":"ded5a7907c6f5d1b7b7fa4e5c8c6cc445bd4a450"},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint\n\nfilepath = \"weights.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='loss',\n                             verbose=1, save_best_only=True,\n                             mode='min')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"57f9ab71278ec6584dc3f2a4166b292d3d79163d"},"cell_type":"code","source":"from keras.callbacks import ReduceLROnPlateau\nreduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2,\n                              patience=1, min_lr=0.001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"87f151c81b294538020863d07466c9bebee2c1ea"},"cell_type":"code","source":"callbacks = [print_callback, checkpoint, reduce_lr]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0898aff47687be0d20c30bc8ba35ada5a6cc446"},"cell_type":"code","source":"model.fit(x, y, batch_size=128, epochs=5, callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"72d813d0114724321428166ffc4b40f2cbb3a809"},"cell_type":"markdown","source":"<a id=\"5\"></a> \n## 5. Generate new text\n\n\nWe can generate text using the same approach as in the on_epoch_end helper function create by Keras."},{"metadata":{"trusted":true,"_uuid":"9d2f2eb1e7fec259e85a982e1cff85a9ee8603e2"},"cell_type":"code","source":"def generate_text(length, diversity):\n    # Get random starting text\n    start_index = random.randint(0, len(text) - maxlen - 1)\n    generated = ''\n    sentence = text[start_index: start_index + maxlen]\n    generated += sentence\n    for i in range(length):\n            x_pred = np.zeros((1, maxlen, len(chars)))\n            for t, char in enumerate(sentence):\n                x_pred[0, t, char_indices[char]] = 1.\n\n            preds = model.predict(x_pred, verbose=0)[0]\n            next_index = sample(preds, diversity)\n            next_char = indices_char[next_index]\n\n            generated += next_char\n            sentence = sentence[1:] + next_char\n    return generated","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b295df279033867aa825ca903e96744b2fd10d8c"},"cell_type":"code","source":"print(generate_text(500, 0.2))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f93a5fa5593130757a2e36409e0cfee68b53b939"},"cell_type":"markdown","source":"<a id=\"6\"></a> \n## 6. Conclusion\n\n\nAfter 5 epochs our LSTM performed a ok job and I'm more than satisfied with the result.\n\nHere are a few things you can change to get better results\n\n1. Add more LSTM Layers.\n2. Use more LSTM Cells.\n3. Train for more than 5 epochs. (25+)\n4. Add dropout Layer.\n5. Play around with the batch-size\n\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}